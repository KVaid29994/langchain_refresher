{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552d1052",
   "metadata": {},
   "source": [
    "## **What is the models Component?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d862b8dd",
   "metadata": {},
   "source": [
    "In LangChain, the models component is a foundational part of the framework. It acts as the interface between LangChain and various language models, including large language models (LLMs), chat models, and text embedding models. This component provides the abstraction needed to use models from different providers (e.g., OpenAI, Cohere, Anthropic, HuggingFace) in a unified and consistent way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999649d",
   "metadata": {},
   "source": [
    "The models component in LangChain:\n",
    "\n",
    "- Standardizes how you interact with language models.\n",
    "\n",
    "- Wraps third-party APIs or open-source LLMs (like GPT-4, Claude, LLaMA, Mistral, etc.).\n",
    "\n",
    "- Allows swapping models without changing the rest of your code.\n",
    "\n",
    "- Supports different types of models, such as:\n",
    "\n",
    "- LLMs: for text generation\n",
    "\n",
    "- Chat models: for message-based interactions\n",
    "\n",
    "- Embedding models: for generating vector representations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af3cef",
   "metadata": {},
   "source": [
    "üß† Key Model Types in LangChain\n",
    "LangChain defines base interfaces for the following types of models:\n",
    "\n",
    "1. LLMs (BaseLLM)\n",
    "- These models generate free-form text.\n",
    "- Examples: OpenAI‚Äôs text-davinci-003, Cohere's command models.\n",
    "- Use-case: summarization, text generation, QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e7b50a",
   "metadata": {},
   "source": [
    "2. Chat Models (BaseChatModel)\n",
    "- Modeled after tools like ChatGPT and Claude that use conversational context.\n",
    "- Accept structured input as ChatMessage objects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a2c605",
   "metadata": {},
   "source": [
    "3. Embedding Models (BaseEmbedding)\n",
    "- Convert text into vector embeddings for semantic search or similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa70097",
   "metadata": {},
   "source": [
    "| Aspect              | Details                                                                |\n",
    "| ------------------- | ---------------------------------------------------------------------- |\n",
    "| Purpose             | Interface to LLMs, chat models, and embeddings                         |\n",
    "| Key types           | `LLM`, `ChatModel`, `Embeddings`                                       |\n",
    "| Supported Providers | OpenAI, Cohere, Anthropic, HuggingFace, Google, etc.                   |\n",
    "| Benefits            | Standardization, modularity, and easy integration with LangChain tools |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180da9e",
   "metadata": {},
   "source": [
    "| Feature                     | LLMs (Large Language Models)                           | Chat Models (e.g., ChatGPT, Claude)                          |\n",
    "|----------------------------|--------------------------------------------------------|-------------------------------------------------------------|\n",
    "| **Purpose**                | General-purpose models for text generation and NLP     | Optimized for conversational, turn-based interactions       |\n",
    "| **Training Objective**     | Predict next token in a large corpus of text           | Fine-tuned with supervised and reinforcement learning for dialogue |\n",
    "| **Memory / Context**       | Stateless (no memory of prior prompts by default)      | Can handle multi-turn dialogue, some have short-term memory |\n",
    "| **Instruction Following**  | Basic to strong, depending on fine-tuning              | Specifically tuned for following instructions               |\n",
    "| **Use Cases**              | Writing, summarization, code, Q&A, translation         | Chatbots, virtual assistants, interactive agents            |\n",
    "| **Response Format**        | Open-ended text or completion                          | Dialogue-like format with more human-like responses         |\n",
    "| **Fine-tuning**            | Needs extra work for task-specific tuning              | Already fine-tuned for conversational flow                  |\n",
    "| **Examples**               | GPT-3, LLaMA, MPT, PaLM                                 | ChatGPT, Claude, Gemini Chat, Mistral Chat                  |\n",
    "| **API Access**             | Often exposed as completion endpoint                   | Exposed as chat endpoint with message-role format           |\n",
    "| **Multi-turn Capability**  | Limited unless manually implemented                    | Built-in support for multi-turn conversations               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ae035",
   "metadata": {},
   "source": [
    "## OPENAI LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fd5aab",
   "metadata": {},
   "source": [
    "| Model           | Release | Key Features                                                               | Usage Scope                              |\n",
    "| --------------- | ------- | -------------------------------------------------------------------------- | ---------------------------------------- |\n",
    "| `gpt-3.5-turbo` | 2023    | Fast, cost-effective, optimized for chat                                   | Assistants, FAQs, general tasks          |\n",
    "| `gpt-4`         | 2023    | More accurate, reasoning-oriented                                          | Coding, tutoring, knowledge tasks        |\n",
    "| `gpt-4-turbo`   | 2023-24 | Cheaper, faster version of GPT-4 (bigger context window up to 128k tokens) | Chatbots, agents, document Q\\&A          |\n",
    "| `gpt-4o`        | 2024    | Multimodal (text, vision, audio), faster + cheaper                         | Advanced agents, visual + audio analysis |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae026ad",
   "metadata": {},
   "source": [
    "## **üß© Integration Features in LangChain v0.2.x+**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6450791e",
   "metadata": {},
   "source": [
    "| Feature               | Description                                                |\n",
    "| --------------------- | ---------------------------------------------------------- |\n",
    "| **Runnables**         | Modular building blocks (for chains, prompts, retrievers)  |\n",
    "| **LCEL**              | LangChain Expression Language for compact pipelines        |\n",
    "| **Chat Templates**    | Chat message formatting for OpenAI‚Äôs `chat/completions`    |\n",
    "| **Streaming Support** | Real-time token streaming with `OpenAI` and `ChatOpenAI`   |\n",
    "| **Tool Calling**      | Native support for OpenAI's `function_call` and `tool_use` |\n",
    "| **Callback System**   | For tracing, logging, and debugging chains                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14182531",
   "metadata": {},
   "source": [
    "## üîß Core Parameters in a Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d0691",
   "metadata": {},
   "source": [
    "| Parameter           | Type           | Description                                                                    |\n",
    "| ------------------- | -------------- | ------------------------------------------------------------------------------ |\n",
    "| `model`             | string         | Name of the model (e.g., `\"gpt-4\"`, `\"gpt-3.5-turbo\"`)                         |\n",
    "| `temperature`       | float (0-2)    | Controls randomness in output. Lower = more deterministic.                     |\n",
    "| `max_tokens`        | int            | Maximum number of tokens to generate in the response.                          |\n",
    "| `top_p`             | float (0-1)    | Nucleus sampling: limits output to tokens within top P cumulative probability. |\n",
    "| `frequency_penalty` | float          | Penalizes repetition of words/phrases.                                         |\n",
    "| `presence_penalty`  | float          | Encourages introducing new topics by penalizing already-used ones.             |\n",
    "| `stop`              | string or list | Stop generating when one of these strings is found.                            |\n",
    "| `stream`            | bool           | If true, enables token-by-token streaming.                                     |\n",
    "| `n`                 | int            | Number of completions to generate (parallel sampling).                         |\n",
    "| `logprobs`          | int/null       | If set, returns the log-probabilities of top tokens.                           |\n",
    "| `echo`              | bool           | Echo back the prompt in the output.                                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7058d",
   "metadata": {},
   "source": [
    "## LangChain also allows parameters like:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4a1b8",
   "metadata": {},
   "source": [
    "| Parameter   | Purpose                                            |\n",
    "| ----------- | -------------------------------------------------- |\n",
    "| `verbose`   | Enables logging of what's happening under the hood |\n",
    "| `callbacks` | Track execution (for tracing, metrics, etc.)       |\n",
    "| `tools`     | (Chat only) Provide external tools for agent use   |\n",
    "| `functions` | (OpenAI-specific) for `function_calling`           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbb074",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f38371",
   "metadata": {},
   "source": [
    "## ***Recommended settings***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e9886",
   "metadata": {},
   "source": [
    "| Use Case                      | `temperature` | `top_p` | `max_tokens` | `frequency_penalty` | `presence_penalty` | Notes                            |\n",
    "| ----------------------------- | ------------- | ------- | ------------ | ------------------- | ------------------ | -------------------------------- |\n",
    "| **Chatbot (Friendly)**        | 0.7           | 1.0     | 512‚Äì1024     | 0.0                 | 0.6                | Balanced, engaging replies       |\n",
    "| **Chatbot (Formal/Support)**  | 0.3           | 1.0     | 512          | 0.2                 | 0.0                | Reliable and accurate            |\n",
    "| **Creative Writing**          | 0.9‚Äì1.2       | 0.85    | 1024‚Äì2048    | 0.0                 | 0.5                | Adds randomness and novelty      |\n",
    "| **Summarization**             | 0.2‚Äì0.4       | 1.0     | 512‚Äì1024     | 0.0                 | 0.0                | Keep it factual and consistent   |\n",
    "| **Code Generation**           | 0.2‚Äì0.3       | 1.0     | 1024‚Äì2048    | 0.0                 | 0.0                | Low randomness = better accuracy |\n",
    "| **Data Extraction / Parsing** | 0.0           | 1.0     | 256‚Äì512      | 0.0                 | 0.0                | Deterministic results            |\n",
    "| **Story Generation**          | 1.0‚Äì1.3       | 0.8     | 1024‚Äì2048    | 0.0                 | 0.8                | High creativity and exploration  |\n",
    "| **Translation**               | 0.3‚Äì0.5       | 1.0     | 512          | 0.0                 | 0.0                | Controlled creativity            |\n",
    "| **Brainstorming Ideas**       | 0.8‚Äì1.2       | 0.85    | 512‚Äì1024     | 0.0                 | 0.8                | Encourage novelty                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba2c45",
   "metadata": {},
   "source": [
    "# ***ü§ñ Open Source vs Closed Source AI Models***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc79958",
   "metadata": {},
   "source": [
    "üü¢ What is an Open Source Model?\n",
    "An open-source model is one whose weights, architecture, and often training data/code are publicly accessible. Developers and researchers can:\n",
    "\n",
    "üõ†Ô∏è Modify it\n",
    "\n",
    "üß™ Fine-tune it\n",
    "\n",
    "üöÄ Deploy it in their own apps\n",
    "\n",
    "ü§ù Share improvements with the community\n",
    "\n",
    "üí° Examples of Open Source Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7405e7f",
   "metadata": {},
   "source": [
    "| Model                | Organization | Purpose                                             |\n",
    "| -------------------- | ------------ | --------------------------------------------------- |\n",
    "| **LLaMA 3**          | Meta         | Large language model (chatbot, summarization, etc.) |\n",
    "| **Mistral 7B**       | Mistral      | Fast and efficient general-purpose LLM              |\n",
    "| **Falcon**           | TII          | Middle Eastern multilingual LLM                     |\n",
    "| **Mixtral**          | Mistral      | Mixture-of-Experts LLM                              |\n",
    "| **Stable Diffusion** | Stability AI | Image generation from text prompts                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67023d63",
   "metadata": {},
   "source": [
    "üîí What is a Closed Source Model?\n",
    "A closed-source model is owned by a company and its weights, architecture, or training data are not publicly released. Users can only:\n",
    "\n",
    "üí¨ Use it through APIs\n",
    "\n",
    "üí∏ Pay-per-use or subscription\n",
    "\n",
    "‚ùå Not modify or self-host\n",
    "\n",
    "üí° Examples of Closed Source Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517027e",
   "metadata": {},
   "source": [
    "| Model          | Organization    | Purpose                                 |\n",
    "| -------------- | --------------- | --------------------------------------- |\n",
    "| **GPT-4**      | OpenAI          | Advanced chatbot and coding assistant   |\n",
    "| **Claude**     | Anthropic       | Friendly assistant optimized for safety |\n",
    "| **Gemini**     | Google DeepMind | Multimodal LLM (text, image, code)      |\n",
    "| **Command R+** | Cohere          | Retrieval-augmented generation          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6f0e91",
   "metadata": {},
   "source": [
    "| Feature               | üü¢ Open Source            | üîí Closed Source                 |\n",
    "| --------------------- | ------------------------- | -------------------------------- |\n",
    "| **Access**            | Free to use & modify      | Limited access (via API only)    |\n",
    "| **Transparency**      | Fully open weights & code | Opaque architecture              |\n",
    "| **Customization**     | Easy to fine-tune         | Hard or impossible               |\n",
    "| **Deployment**        | Can self-host             | Must use provider infrastructure |\n",
    "| **Community Support** | Strong, collaborative     | Limited, company-controlled      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9be399",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kash1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
